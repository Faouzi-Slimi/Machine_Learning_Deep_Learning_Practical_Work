{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faouzi-Slimi/python_Avancee/blob/main/Next_Words_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qz_qe5S5xWj8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import layers,Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM,Bidirectional,GRU\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=\"\"\"Artificial Intelligence (AI) is a technical science that studies and develops theories, methods, technologies, and applications for simulating and extending human intelligence. The purpose of AI is to enable machines to think like\n",
        "people and to make machines intelligent. Today, AI has become an interdisciplinary course that involves various fields.\"\"\""
      ],
      "metadata": {
        "id": "l1L63poTxnfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "words=tokenizer.fit_on_texts([data])"
      ],
      "metadata": {
        "id": "sO3kYTBDWROT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n"
      ],
      "metadata": {
        "id": "1ozGRzJzYDdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aae29f6-405f-4864-8130-4729ef0b0fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 6,\n",
              " 12,\n",
              " 1,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 1,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 1,\n",
              " 20,\n",
              " 21,\n",
              " 4,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 25,\n",
              " 7,\n",
              " 3,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 1,\n",
              " 3,\n",
              " 29,\n",
              " 7,\n",
              " 30,\n",
              " 31,\n",
              " 2,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 6,\n",
              " 37,\n",
              " 38,\n",
              " 39]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequence_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcnJZMugxtpk",
        "outputId": "b63432b6-4f15-4cbf-df69-30c1f13b1400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqyV1xesxxOs",
        "outputId": "18d281be-4e68-4b3d-b92f-e153c92098c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 6,\n",
              " 12,\n",
              " 1,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 1,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 1,\n",
              " 20,\n",
              " 21,\n",
              " 4,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 25,\n",
              " 7,\n",
              " 3,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 1,\n",
              " 3,\n",
              " 29,\n",
              " 7,\n",
              " 30,\n",
              " 31,\n",
              " 2,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 6,\n",
              " 37,\n",
              " 38,\n",
              " 39]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X= []\n",
        "\n",
        "for i in range(len(sequence_data)-1):\n",
        "    words=sequence_data[i]\n",
        "    X.append(words)\n",
        "    \n",
        "    \n",
        "X= np.array(X)"
      ],
      "metadata": {
        "id": "LNmiLQPQxzpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWEWxwpfx3AT",
        "outputId": "591cc19a-9f21-4df4-efe5-3be8adcaeedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQFlEibdx73M",
        "outputId": "93e760fc-5a2d-42b4-84df-d17ad334c04e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  4,  2,  5,  9, 10, 11,  6, 12,  1, 13, 14, 15, 16,  1, 17, 18,\n",
              "       19,  1, 20, 21,  4, 22, 23, 24,  2,  5,  3, 25,  7,  3, 26, 27, 28,\n",
              "        1,  3, 29,  7, 30, 31,  2, 32, 33, 34, 35, 36,  6, 37, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlc0y7F-yAoR",
        "outputId": "a938b60c-61f9-44cf-826e-cd295b281a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  4,  2,  5,  9, 10, 11,  6, 12,  1, 13, 14, 15, 16,  1, 17, 18,\n",
              "       19,  1, 20, 21,  4, 22, 23, 24,  2,  5,  3, 25,  7,  3, 26, 27, 28,\n",
              "        1,  3, 29,  7, 30, 31,  2, 32, 33, 34, 35, 36,  6, 37, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y= []\n",
        "\n",
        "for i in range(1,len(sequence_data)):\n",
        "    words=sequence_data[i]\n",
        "    Y.append(words)\n",
        "    \n",
        "    \n",
        "Y = np.array(Y)\n"
      ],
      "metadata": {
        "id": "Y1BgHswlZYJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm3fU4KncqYM",
        "outputId": "3ee084c6-9dc1-497b-ee05-9ff573dd20e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZuNtBSPdRGt",
        "outputId": "80ee1534-6edf-4cd4-c64e-418cac906c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4,  2,  5,  9, 10, 11,  6, 12,  1, 13, 14, 15, 16,  1, 17, 18, 19,\n",
              "        1, 20, 21,  4, 22, 23, 24,  2,  5,  3, 25,  7,  3, 26, 27, 28,  1,\n",
              "        3, 29,  7, 30, 31,  2, 32, 33, 34, 35, 36,  6, 37, 38, 39])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "vDh0rc5DzQI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3moY-U0zm6g",
        "outputId": "fc57f539-4df2-48fd-ed25-e0e31e9228fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and': 1,\n",
              " 'ai': 2,\n",
              " 'to': 3,\n",
              " 'intelligence': 4,\n",
              " 'is': 5,\n",
              " 'that': 6,\n",
              " 'machines': 7,\n",
              " 'artificial': 8,\n",
              " 'a': 9,\n",
              " 'technical': 10,\n",
              " 'science': 11,\n",
              " 'studies': 12,\n",
              " 'develops': 13,\n",
              " 'theories': 14,\n",
              " 'methods': 15,\n",
              " 'technologies': 16,\n",
              " 'applications': 17,\n",
              " 'for': 18,\n",
              " 'simulating': 19,\n",
              " 'extending': 20,\n",
              " 'human': 21,\n",
              " 'the': 22,\n",
              " 'purpose': 23,\n",
              " 'of': 24,\n",
              " 'enable': 25,\n",
              " 'think': 26,\n",
              " 'like': 27,\n",
              " 'people': 28,\n",
              " 'make': 29,\n",
              " 'intelligent': 30,\n",
              " 'today': 31,\n",
              " 'has': 32,\n",
              " 'become': 33,\n",
              " 'an': 34,\n",
              " 'interdisciplinary': 35,\n",
              " 'course': 36,\n",
              " 'involves': 37,\n",
              " 'various': 38,\n",
              " 'fields': 39}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4efRWRTVzwtv",
        "outputId": "ba3cc95b-696f-4c30-a9e6-47aebcecd597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,40, input_length=1))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "Hb5COEL4yYtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = to_categorical(Y, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "6ovWBnHV0Cfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwGrVZTGymZO",
        "outputId": "7f2aabb2-0575-4ae8-d8b1-c77e101c9d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 5s 124ms/step - loss: 3.6895 - accuracy: 0.0408\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 3.6854 - accuracy: 0.0816\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 3.6802 - accuracy: 0.0816\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 3.6747 - accuracy: 0.0816\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 3.6666 - accuracy: 0.0816\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 3.6544 - accuracy: 0.0816\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 3.6370 - accuracy: 0.0816\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 3.6107 - accuracy: 0.0816\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 3.5751 - accuracy: 0.0816\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 3.5279 - accuracy: 0.0816\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 3.4865 - accuracy: 0.0816\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 3.4578 - accuracy: 0.0816\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 3.4334 - accuracy: 0.0816\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 3.3796 - accuracy: 0.0816\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 3.3043 - accuracy: 0.0816\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 3.2303 - accuracy: 0.0816\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 3.1623 - accuracy: 0.1224\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 3.0951 - accuracy: 0.1429\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 3.0245 - accuracy: 0.1633\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 2.9372 - accuracy: 0.2245\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 2.8325 - accuracy: 0.2041\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 2.7216 - accuracy: 0.2653\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 2.5966 - accuracy: 0.2449\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 2.4564 - accuracy: 0.2245\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 2.3559 - accuracy: 0.2245\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 2.2365 - accuracy: 0.3061\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 2.1107 - accuracy: 0.3469\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 2.0172 - accuracy: 0.3469\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.8777 - accuracy: 0.3878\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.7714 - accuracy: 0.4082\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.6608 - accuracy: 0.3878\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 1.5628 - accuracy: 0.4082\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 1.4413 - accuracy: 0.4490\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 1.3272 - accuracy: 0.5510\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.2244 - accuracy: 0.6327\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 1.1491 - accuracy: 0.6122\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 1.0540 - accuracy: 0.5918\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 0.9820 - accuracy: 0.6327\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.9201 - accuracy: 0.6531\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.8338 - accuracy: 0.6735\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.7811 - accuracy: 0.7143\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.7315 - accuracy: 0.6735\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.6347 - accuracy: 0.7347\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.5778 - accuracy: 0.7347\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.5648 - accuracy: 0.7755\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.5327 - accuracy: 0.7959\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.4945 - accuracy: 0.7551\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.4517 - accuracy: 0.7755\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.4716 - accuracy: 0.7959\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.4842 - accuracy: 0.7755\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.4709 - accuracy: 0.7755\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.4307 - accuracy: 0.8163\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.4485 - accuracy: 0.7959\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.4087 - accuracy: 0.7959\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.4138 - accuracy: 0.7959\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 0.3972 - accuracy: 0.7959\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.4246 - accuracy: 0.7959\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 0.4021 - accuracy: 0.7755\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.3860 - accuracy: 0.7959\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.3806 - accuracy: 0.7959\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3792 - accuracy: 0.7551\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.3681 - accuracy: 0.7959\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.3801 - accuracy: 0.7755\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.3786 - accuracy: 0.7755\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.3763 - accuracy: 0.7347\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.3568 - accuracy: 0.7551\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.3660 - accuracy: 0.7347\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.3633 - accuracy: 0.7959\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.3545 - accuracy: 0.7755\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.3754 - accuracy: 0.7959\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.3754 - accuracy: 0.7959\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.3681 - accuracy: 0.7959\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.3587 - accuracy: 0.7755\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.3680 - accuracy: 0.7959\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.3667 - accuracy: 0.7959\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.3672 - accuracy: 0.7551\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.3565 - accuracy: 0.7959\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.3776 - accuracy: 0.7959\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.3702 - accuracy: 0.7959\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.3662 - accuracy: 0.7959\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 0.3673 - accuracy: 0.8163\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.3604 - accuracy: 0.7959\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.3726 - accuracy: 0.7959\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 0.3662 - accuracy: 0.7755\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 0.3517 - accuracy: 0.7959\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.3510 - accuracy: 0.7551\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.3438 - accuracy: 0.7959\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.3524 - accuracy: 0.7755\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.3577 - accuracy: 0.7959\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 281ms/step - loss: 0.3469 - accuracy: 0.7959\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.3558 - accuracy: 0.7959\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 0.3483 - accuracy: 0.8163\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.3553 - accuracy: 0.7755\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.3729 - accuracy: 0.7959\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 197ms/step - loss: 0.3559 - accuracy: 0.7551\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.3476 - accuracy: 0.7755\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 0.3501 - accuracy: 0.7959\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.3509 - accuracy: 0.7959\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 0.3499 - accuracy: 0.7959\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 0.3475 - accuracy: 0.7755\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcc55349290>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dimreAcIn5fv",
        "outputId": "5bacf87a-b21e-4a74-ab1e-23b6bc6a1f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('and', 1), ('ai', 2), ('to', 3), ('intelligence', 4), ('is', 5), ('that', 6), ('machines', 7), ('artificial', 8), ('a', 9), ('technical', 10), ('science', 11), ('studies', 12), ('develops', 13), ('theories', 14), ('methods', 15), ('technologies', 16), ('applications', 17), ('for', 18), ('simulating', 19), ('extending', 20), ('human', 21), ('the', 22), ('purpose', 23), ('of', 24), ('enable', 25), ('think', 26), ('like', 27), ('people', 28), ('make', 29), ('intelligent', 30), ('today', 31), ('has', 32), ('become', 33), ('an', 34), ('interdisciplinary', 35), ('course', 36), ('involves', 37), ('various', 38), ('fields', 39)])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=input()\n",
        "wordval = tokenizer.texts_to_sequences([word])[0]\n",
        "pred=model.predict(wordval)\n",
        "pred2=np.argmax(pred)\n",
        "for key, values in tokenizer.word_index.items():\n",
        "        if  values == pred2:\n",
        "            nextword=key\n",
        "            print(nextword)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RToA_EsQzAiR",
        "outputId": "d856f505-1e21-441a-94d9-f143d518f0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "technical\n",
            "science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3vm8blNto0V",
        "outputId": "f1c51bc7-36f8-46ec-c8fb-1fe05562178d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRSii8Y6tw7R",
        "outputId": "0f50fa2e-7b1b-4ce8-ba39-8401d985974d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.09345512e-22, 2.87982577e-04, 7.11975929e-07, 1.01182386e-05,\n",
              "        9.98656392e-01, 3.49365719e-13, 3.12959741e-10, 1.02363294e-03,\n",
              "        1.01829175e-21, 6.69888004e-06, 8.17006900e-15, 4.54693307e-21,\n",
              "        1.76197941e-17, 4.41300614e-08, 3.85786516e-17, 1.05010436e-07,\n",
              "        5.77022888e-07, 1.45365151e-08, 1.44119065e-14, 2.83453470e-19,\n",
              "        5.08604749e-08, 4.99322653e-07, 1.31793404e-05, 1.43366944e-19,\n",
              "        2.61358730e-12, 8.12432725e-21, 3.34351858e-19, 6.62308773e-16,\n",
              "        3.66712508e-19, 1.14596788e-19, 2.82494056e-10, 2.90076938e-11,\n",
              "        3.29917343e-12, 2.85868789e-17, 6.18327487e-15, 3.39412303e-20,\n",
              "        3.49210090e-19, 9.66236622e-18, 6.09675427e-15, 2.69059026e-13]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEdL7S09nObY",
        "outputId": "89ceb119-f92b-4283-c16b-69459f420e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=input()\n",
        "wordval = tokenizer.texts_to_sequences([word])[0]\n",
        "pred=model.predict(wordval)\n",
        "pred2=np.argmax(pred,axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aObmjxmDpLqv",
        "outputId": "69fdf16e-f4b5-4edf-a641-5973bc1557f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "artificial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nextword=tokenizer.sequences_to_texts([pred2])"
      ],
      "metadata": {
        "id": "GDnDF9VbwDtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nextword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4k-u9urxq80",
        "outputId": "a6d514b0-b08f-478e-983f-ef018237db5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['intelligence']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,40, input_length=1))\n",
        "model.add(Bidirectional(LSTM(1000, return_sequences=True)))\n",
        "model.add(Bidirectional(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size, activation=\"softmax\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Y4lfHiwQye1H",
        "outputId": "95fc958e-4602-4889-c01c-d10ffe9e7d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-441ec7646e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, merge_mode, weights, backward_layer, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m       raise ValueError(\n\u001b[0;32m--> 454\u001b[0;31m           \u001b[0;34m'Please initialize `Bidirectional` layer with a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m           f'`tf.keras.layers.Layer` instance. Received: {layer}')\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackward_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackward_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please initialize `Bidirectional` layer with a `tf.keras.layers.Layer` instance. Received: 1000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2iXOpNZ8JnT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}