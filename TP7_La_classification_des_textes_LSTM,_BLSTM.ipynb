{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_cVu1VR9jpFndZ4zKYwkAL2LyX_CVCaC",
      "authorship_tag": "ABX9TyMQsQM8wKmzepONAbxjKszv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faouzi-Slimi/python_Avancee/blob/main/TP7_La_classification_des_textes_LSTM%2C_BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "71CliBeT2sb8"
      },
      "outputs": [],
      "source": [
        "# Import Libray\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/spam.csv\",delimiter = \",\",encoding = \"latin-1\")"
      ],
      "metadata": {
        "id": "_wtw2V655u0o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Data\n",
        "\n",
        "data1 = data.drop([\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],axis = 1)\n",
        "\n",
        "X = data1.v2\n",
        "Y = data1.v1"
      ],
      "metadata": {
        "id": "fCkVS0EC6dX4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoder\n",
        "\n",
        "le =  LabelEncoder()\n",
        "Y1 = le.fit_transform(Y)\n",
        "Y2 = Y1.reshape(-1,1)\n",
        "\n",
        "\n",
        "max_words = 1000\n",
        "max_len=150\n",
        "\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X)\n",
        "sequences = tok.texts_to_sequences(X)\n",
        "\n",
        "sequence_matrix = sequence.pad_sequences(sequences,maxlen = max_len)"
      ],
      "metadata": {
        "id": "2J553PVO60aS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tvHm8Hc28JtZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}